# Auto Model Selection

> Automatically select the best AI model for your prompts using OpenRouter's Auto Router powered by NotDiamond.

The [Auto Router](https://openrouter.ai/openrouter/auto) is a special model ID that automatically chooses between selected high-quality models based on your prompt, powered by [NotDiamond](https://www.notdiamond.ai/).

## How to Use

Simply set your model to `openrouter/auto` and OpenRouter will intelligently select the best model for your specific prompt.

<CodeGroup>
  ```typescript title="TypeScript SDK"
  import { OpenRouter } from '@openrouter/sdk';

  const openRouter = new OpenRouter({
    apiKey: '<OPENROUTER_API_KEY>',
  });

  const completion = await openRouter.chat.send({
    model: 'openrouter/auto',
    messages: [
      {
        role: 'user',
        content: 'What is the meaning of life?',
      },
    ],
  });

  console.log(completion.choices[0].message.content);
  ```

  ```typescript title="TypeScript (fetch)"
  const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': 'Bearer <OPENROUTER_API_KEY>',
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'openrouter/auto',
      messages: [
        {
          role: 'user',
          content: 'What is the meaning of life?',
        },
      ],
    }),
  });

  const data = await response.json();
  console.log(data.choices[0].message.content);
  ```

  ```python title="Python"
  import requests
  import json

  response = requests.post(
    url="https://openrouter.ai/api/v1/chat/completions",
    headers={
      "Authorization": "Bearer <OPENROUTER_API_KEY>",
      "Content-Type": "application/json",
    },
    data=json.dumps({
      "model": "openrouter/auto",
      "messages": [
        {
          "role": "user",
          "content": "What is the meaning of life?"
        }
      ]
    })
  )

  data = response.json()
  print(data['choices'][0]['message']['content'])
  ```
</CodeGroup>

## Response

The resulting generation will have `model` set to the model that was actually used for your request, allowing you to track which model was selected.
