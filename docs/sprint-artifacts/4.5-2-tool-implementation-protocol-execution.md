# Story 4.5.2: Tool Implementation & Protocol Execution

Status: ready-for-dev

<!--
VALIDATION UPDATES (2025-12-22):
This story has been revised based on comprehensive validation findings.
See: validation-report-20251222-205544.md

KEY CHANGES:
1. Git Implementation: Changed from shell commands to reusing git2-rs from Story 3.2 (prevents duplicate functionality)
2. Security: Enhanced validate_tool_path with database project validation
3. Context Injection: Added wrapper architecture for automatic context injection + tool logging
4. Protocol Execution: Clarified that protocol steps are guidance, not strict execution order
5. Attribution: Enhanced with YAML frontmatter format for Story 4.5.3 integration

All 5 critical issues, 4 enhancements, and 4 LLM optimizations applied.
-->

<!-- Note: Validation is optional. Run validate-create-story for quality check before dev-story. -->

## Dependencies

**Requires (must be completed first):**
- Story 4.5.1: Agent Core & System Prompt (mock tools exist, reasoning store ready, Vercel SDK client working)

**Blocks (cannot start until this is done):**
- Story 4.5.3: Agent Route & UI (requires working protocol execution to build UI around)

**Key Context from Previous Story:**
Story 4.5.1 created the agent core infrastructure with MOCK tools. This story replaces those mocks with REAL Tauri command implementations and creates the "Project Resurrection" protocol that autonomously analyzes dormant projects.

## Story

As a **developer**,
I want **real tool implementations and protocol execution logic**,
So that **Ronin-Thinking can analyze projects autonomously using actual file system and git data**.

## Acceptance Criteria

### 1. Tool Implementation - Backend (Rust Tauri Commands)

**Given** the reasoning agent needs to interact with the project file system and git
**When** implementing tool commands
**Then** the following Tauri commands are created:

**A. read_file Command (src-tauri/src/commands/tools.rs - NEW)**
- [ ] Command signature: `read_file(project_path: String, file_path: String) -> Result<String, String>`
- [ ] Resolves file path relative to project root
- [ ] Security: ONLY allows reading files within tracked project directories
- [ ] Security: Blocks reading from system paths (/etc, /home/user/.ssh, etc.)
- [ ] Returns file content as UTF-8 string
- [ ] Error handling: File not found, permission denied, binary file, path traversal attempts
- [ ] Maximum file size: 1MB (prevents memory issues with large files)
- [ ] Binary file detection: Return error if file is binary (not readable as text)

**B. list_dir Command (src-tauri/src/commands/tools.rs)**
- [ ] Command signature: `list_dir(project_path: String, dir_path: String) -> Result<Vec<FileEntry>, String>`
- [ ] Returns list of files/folders with metadata:
  ```rust
  struct FileEntry {
      name: String,
      path: String,           // Relative to project root
      is_dir: bool,
      size: u64,              // In bytes
      modified: i64,          // Unix timestamp
  }
  ```
- [ ] Security: ONLY allows listing within tracked project directories
- [ ] Sorts entries: directories first (alphabetical), then files (alphabetical)
- [ ] Maximum depth: Non-recursive (single level) to prevent performance issues
- [ ] Filters: Ignores hidden files (.git/, .DS_Store) by default
- [ ] Error handling: Directory not found, permission denied, path traversal

**C. git_status Command (src-tauri/src/commands/tools.rs)**
- [ ] **IMPORTANT:** Reuse existing `get_git_status` from `src-tauri/src/commands/git.rs` (Story 3.2)
- [ ] Command signature: `git_status(project_path: String) -> Result<GitStatus, String>`
- [ ] Implementation approach:
  ```rust
  use crate::commands::git::{get_git_status, GitStatus};

  #[tauri::command]
  pub async fn git_status(project_path: String) -> Result<GitStatus, String> {
      validate_tool_path(&project_path, ".")?; // Security layer
      get_git_status(project_path).await        // Reuse existing
  }
  ```
- [ ] Existing `GitStatus` struct from git.rs (lines 17-20):
  ```rust
  pub struct GitStatus {
      pub is_clean: bool,
      pub modified_files: Vec<String>,
  }
  ```
- [ ] **If additional fields needed** (branch, has_remote), extend GitStatus in git.rs first
- [ ] Uses git2-rs library (already implemented, tested, faster than shell commands)
- [ ] Error handling: Already implemented in get_git_status
- [ ] Performance: < 500ms for typical repos (git2-rs is faster than shell)

**D. git_log Command (src-tauri/src/commands/tools.rs)**
- [ ] **IMPORTANT:** Reuse existing `get_git_history` from `src-tauri/src/commands/git.rs` (Story 3.2)
- [ ] Command signature: `git_log(project_path: String, limit: Option<usize>) -> Result<Vec<GitCommit>, String>`
- [ ] Implementation approach:
  ```rust
  use crate::commands::git::{get_git_history, GitCommit};

  #[tauri::command]
  pub async fn git_log(project_path: String, limit: Option<usize>) -> Result<Vec<GitCommit>, String> {
      validate_tool_path(&project_path, ".")?; // Security layer
      get_git_history(project_path, limit).await // Reuse existing
  }
  ```
- [ ] Existing `GitCommit` struct from git.rs (lines 7-14):
  ```rust
  pub struct GitCommit {
      pub sha: String,
      pub author: String,
      pub date: String,
      pub message: String,
      pub files: Vec<String>,
  }
  ```
- [ ] Default limit: 20 commits, max: 50 (parameter validation in wrapper)
- [ ] Uses git2-rs library (already implemented and tested)
- [ ] Error handling: Already implemented in get_git_history
- [ ] Performance: < 1s for 50 commits

**E. Tool Result Caching (src-tauri/src/commands/tools.rs) - OPTIONAL PERFORMANCE ENHANCEMENT**
- [ ] Implement simple in-memory cache with 60s TTL for git operations:
  ```rust
  use std::collections::HashMap;
  use std::time::{Instant, Duration};
  use tokio::sync::Mutex;

  lazy_static! {
      static ref TOOL_CACHE: Mutex<ToolCache> = Mutex::new(ToolCache::new());
  }

  struct ToolCache {
      git_status: HashMap<String, (GitStatus, Instant)>,
      git_history: HashMap<String, (Vec<GitCommit>, Instant)>,
      ttl: Duration,
  }

  impl ToolCache {
      fn new() -> Self {
          Self {
              git_status: HashMap::new(),
              git_history: HashMap::new(),
              ttl: Duration::from_secs(60),
          }
      }

      fn get_git_status(&mut self, path: &str) -> Option<GitStatus> {
          if let Some((cached, time)) = self.git_status.get(path) {
              if time.elapsed() < self.ttl {
                  return Some(cached.clone());  // 500ms ‚Üí 5ms
              }
          }
          None
      }

      fn set_git_status(&mut self, path: String, status: GitStatus) {
          self.git_status.insert(path, (status, Instant::now()));
      }
  }
  ```
- [ ] Cache invalidation on project file changes (optional, can defer to future story)
- [ ] Benefits: Meets <500ms git_status NFR even on slow repos, improves retry performance
- [ ] Mark as optional: Can be implemented after MVP if performance issues occur

**F. Security Layer (src-tauri/src/commands/tools.rs) - CRITICAL FIRST**
- [ ] Create `validate_tool_path` helper function with database validation:
  ```rust
  async fn validate_tool_path(
      db: &SqlitePool,
      project_path: &str,
      requested_path: &str
  ) -> Result<PathBuf, String> {
      // 1. FIRST: Verify project exists in tracked projects database
      let project = sqlx::query!("SELECT id FROM projects WHERE path = ?", project_path)
          .fetch_optional(db)
          .await
          .map_err(|e| format!("Database error: {}", e))?
          .ok_or_else(|| "Project not tracked. Only tracked projects can be accessed.".to_string())?;

      // 2. THEN: Resolve paths to canonical form
      let project_canonical = fs::canonicalize(project_path)
          .map_err(|_| "Project path does not exist".to_string())?;

      let full_path = project_canonical.join(requested_path);
      let requested_canonical = fs::canonicalize(&full_path)
          .map_err(|_| format!("Path not found: {}", requested_path))?;

      // 3. Check path doesn't escape project directory
      if !requested_canonical.starts_with(&project_canonical) {
          return Err("Invalid path: Attempts to escape project directory".to_string());
      }

      // 4. Check for symlink attacks (resolved path must still be within project)
      if requested_canonical != full_path {
          // Path was resolved (symlink), verify it's still within project
          if !requested_canonical.starts_with(&project_canonical) {
              return Err("Symlink attack detected: Link escapes project directory".to_string());
          }
      }

      // 5. Reject system directory access (belt-and-suspenders)
      let system_dirs = ["/etc", "/sys", "/proc", "/dev", "/root"];
      for sys_dir in &system_dirs {
          if requested_canonical.starts_with(sys_dir) {
              return Err(format!("Access denied: Cannot access system directory {}", sys_dir));
          }
      }

      Ok(requested_canonical)
  }
  ```
- [ ] Database parameter passed from all tool commands (access to SqlitePool)
- [ ] Used by ALL tool commands before file operations
- [ ] Returns canonical PathBuf for safe file operations
- [ ] Error messages are user-friendly (‰ªÅ Jin - compassion)

### 2. Tool Integration - Frontend (TypeScript)

**Given** Story 4.5.1 has mock tools in `src/lib/ai/tools/mock/index.ts`
**When** replacing mocks with real implementations
**Then** the following updates are made:

**A. Real Tool Handlers (src/lib/ai/tools/index.ts - MODIFY)**
- [ ] Replace mock implementations with Tauri `invoke` calls
- [ ] Tool execution receives context via second parameter:
  ```typescript
  export const realToolHandlers = {
    read_file: tool({
      description: 'Read file content from project',
      parameters: z.object({
        path: z.string().describe('File path relative to project root'),
      }),
      execute: async ({ path }, context: ToolExecutionContext) => {
        const project = await invoke<Project>('get_project_by_id', { id: context.projectId });
        const content = await invoke<string>('read_file', {
          projectPath: project.path,
          filePath: path,
        });
        return content;
      },
    }),

    list_dir: tool({ /* similar pattern with context parameter */ }),
    git_status: tool({ /* similar pattern with context parameter */ }),
    git_log: tool({ /* similar pattern with context parameter */ }),
  };
  ```
- [ ] Error handling: Show user-friendly errors (not raw Tauri errors)
- [ ] Tool handlers receive context but don't call logger (automatic wrapper handles it)

**B. Tool Execution Context Type (src/lib/ai/tools/types.ts - NEW)**
- [ ] Define `ToolExecutionContext` interface:
  ```typescript
  export interface ToolExecutionContext {
    projectId: number;
    mode: AgentMode;  // 'ronin-flash' | 'ronin-thinking'
    currentStepId?: string;  // Optional: Current protocol step being executed
  }
  ```
- [ ] Export from tools module for use in wrappers

**C. Context Injection Wrapper (src/lib/ai/tools/wrapper.ts - NEW)**
- [ ] Create `wrapToolsWithContext` function to inject context automatically:
  ```typescript
  import { logToolCall } from './logger';
  import type { ToolExecutionContext } from './types';

  export function wrapToolsWithContext(
    tools: Record<string, CoreTool>,
    projectId: number,
    mode: AgentMode,
    getCurrentStepId: () => string | undefined
  ): Record<string, CoreTool> {
    return Object.fromEntries(
      Object.entries(tools).map(([name, tool]) => [
        name,
        {
          ...tool,
          execute: async (params: any) => {
            // Build context
            const context: ToolExecutionContext = {
              projectId,
              mode,
              currentStepId: getCurrentStepId(),
            };

            // Execute tool with context
            const result = await tool.execute(params, context);

            // Automatic logging AFTER execution
            await logToolCall(projectId, name, params, result);

            return result;
          },
        },
      ])
    );
  }
  ```
- [ ] Wrapper handles BOTH context injection AND automatic tool call logging
- [ ] Individual tools don't need manual logging calls

**D. Update AI Client (src/lib/ai/client.ts - MODIFY)**
- [ ] Modify `createTauriLanguageModel` to use wrapper:
  ```typescript
  import { realToolHandlers } from './tools';
  import { wrapToolsWithContext } from './tools/wrapper';
  import { useReasoningStore } from '@/stores/reasoningStore';

  export function createTauriLanguageModel(
    projectId: number,
    mode: AgentMode = 'ronin-flash'
  ): LanguageModel {
    // Get current step ID from reasoning store
    const getCurrentStepId = () => useReasoningStore.getState().currentStepId;

    // Wrap tools with context injection + auto-logging
    const tools = wrapToolsWithContext(
      realToolHandlers,
      projectId,
      mode,
      getCurrentStepId
    );

    return new TauriLanguageModel({ tools, projectId, mode });
  }
  ```
- [ ] Tools receive context automatically, no breaking changes to Story 4.5.1 mock tools needed
- [ ] Migration: Mock tools updated to accept optional second parameter (backward compatible)

**E. Tool Call Logger (src/lib/ai/tools/logger.ts - NEW)**
- [ ] Function signature: `async logToolCall(projectId: number, tool: string, params: any, result: any): Promise<void>`
- [ ] Appends to reasoning store's `stepHistory` with `toolCallsMade` field:
  ```typescript
  import { useReasoningStore } from '@/stores/reasoningStore';

  export async function logToolCall(
    projectId: number,
    toolName: string,
    params: any,
    result: any
  ): Promise<void> {
    const store = useReasoningStore.getState();
    const currentStepId = store.currentStepId || 'unknown';

    // Format tool call for display
    const formattedCall = `${toolName}(${formatParams(params)})`;

    // Append to step history
    store.appendToolCall({
      stepId: currentStepId,
      toolCall: formattedCall,
      timestamp: Date.now(),
    });
  }

  function formatParams(params: any): string {
    if (typeof params === 'string') return params;
    if (params.path) return params.path;
    return JSON.stringify(params);
  }
  ```
- [ ] Called automatically by wrapper (tools don't call this directly)
- [ ] Used for debugging and ThinkingIndicator UI (Story 4.5.3)

### 3. Project Resurrection Protocol Definition

**Given** tools are implemented and working
**When** defining the autonomous analysis protocol
**Then** `src/lib/ai/protocols/project-resurrection.ts` is created:

**A. Protocol Structure:**
- [ ] Protocol ID: `"project-resurrection"`
- [ ] Title: "Deep Project Analysis"
- [ ] Description: "Autonomous analysis of dormant projects using multi-step reasoning"
- [ ] Steps defined:
  ```typescript
  export const PROJECT_RESURRECTION_PROTOCOL: ReasoningProtocol = {
    id: 'project-resurrection',
    title: 'Deep Project Analysis',
    description: 'Multi-step autonomous analysis for context recovery',
    steps: [
      {
        id: 'step-01-discover-structure',
        title: 'Discover Project Structure',
        instruction: 'Use list_dir to map the project layout. Identify key directories (src/, tests/, docs/). Determine project type (web app, library, CLI tool, etc.).',
        requiredOutput: 'none',
      },
      {
        id: 'step-02-read-metadata',
        title: 'Read Project Metadata',
        instruction: 'Read package.json, Cargo.toml, or equivalent manifest. Extract: project name, dependencies, scripts. Use read_file tool.',
        requiredOutput: 'none',
      },
      {
        id: 'step-03-analyze-git',
        title: 'Analyze Git History',
        instruction: 'Use git_status for current state, git_log for recent commits. Identify: last active area, uncommitted work, recent focus.',
        requiredOutput: 'none',
      },
      {
        id: 'step-04-read-devlog',
        title: 'Check for DEVLOG (Optional)',
        instruction: 'Check if DEVLOG.md exists using list_dir. If found, read last 500 lines. Extract manual notes about stuck points or next steps.',
        requiredOutput: 'none',
      },
      {
        id: 'step-05-synthesize',
        title: 'Synthesize Deep Status Report',
        instruction: 'Combine all findings into a structured report with: Last Active Area, Current State (uncommitted changes, test status), Suggested Next Steps (prioritized), Based On attribution.',
        requiredOutput: 'none',
      },
    ],
  };
  ```

**B. Protocol Execution Flow:**
- [ ] **ARCHITECTURAL DECISION: Protocol Steps as Guidance, Not Strict Execution**
  - Protocol steps are INFORMATIONAL GUIDANCE embedded in system prompt
  - System prompt includes: "Follow these 5 analysis steps: [protocol.steps]"
  - LLM autonomously decides tool call sequence (may not follow strict order)
  - No enforcement of step order - LLM can jump, repeat, or skip steps based on findings

- [ ] **Vercel AI SDK Integration:**
  - `maxSteps: 10` is SAFETY LIMIT for total tool calls, NOT protocol step count
  - Each tool call counts toward maxSteps (step-02 might use 3 tool calls)
  - If maxSteps exhausted, protocol returns partial results with message

- [ ] **Step Logging (Implicit):**
  - ReasoningStore tracks currentStepId (set by protocol progress heuristics)
  - Each tool call logged with current step context: `{ stepId: 'step-02', toolCall: 'read_file(...)' }`
  - Step completion is IMPLICIT (no strict validation, UI infers progress from tool calls)

- [ ] **Execution Example:**
  ```typescript
  // System prompt includes protocol:
  "Analyze project following these 5 steps:
  1. Discover structure (use list_dir)
  2. Read metadata (use read_file for package.json)
  3. Analyze git (use git_status, git_log)
  4. Check DEVLOG (optional)
  5. Synthesize report"

  // LLM decides autonomously:
  // - Call list_dir(.) [step-01]
  // - Call read_file(package.json) [step-02]
  // - Call read_file(README.md) [step-02 - additional file]
  // - Call git_log(limit: 10) [step-03]
  // - [Skips step-04 if DEVLOG not found]
  // - Synthesize report in text [step-05]

  // Total tool calls: 4 (well under maxSteps: 10)
  ```

- [ ] Total execution time: < 30s for typical projects (NFR target)
- [ ] Reasoning store updates currentStepId based on tool call patterns (heuristic, not strict)

**C. Attribution Extraction (Enhanced for Story 4.5.3 Integration):**
- [ ] During synthesis step (step-05), system prompt instructs agent to output attribution in structured YAML frontmatter:
  ```
  "When synthesizing Deep Status Report, output attribution in YAML frontmatter:
  ---
  attribution:
    files_read: [package.json, README.md, DEVLOG.md]
    tool_calls: { read_file: 3, list_dir: 1, git_log: 1, git_status: 1 }
    confidence: high
  ---
  [Your Deep Status Report here]
  "
  ```
- [ ] Parsing logic for Story 4.5.3:
  ```typescript
  const match = output.match(/---\nattribution:\n(.*?)\n---/s);
  if (match) {
    const attribution = yaml.parse(match[1]);
    // Story 4.5.3 receives structured data for UI display
  }
  ```
- [ ] Fallback for unstructured output: Parse "Based on: ..." lines from text
- [ ] Story 4.5.3 will display attribution badges (üìñ package.json, üîÄ git history, etc.)

### 4. Error Handling & Edge Cases

**Given** tools can fail in various ways
**When** handling errors during protocol execution
**Then** the following behaviors are implemented:

**A. Tool-Level Errors:**
- [ ] File not found: Return error to LLM, let it adapt (e.g., "DEVLOG.md not found, skipping step 4")
- [ ] Permission denied: Return error, LLM proceeds without that data
- [ ] Binary file: Return error "File is binary, cannot read as text"
- [ ] Path traversal attempt: Return security error, log suspicious behavior

**B. Protocol-Level Errors:**
- [ ] Max steps exhausted (10 steps): Return partial results with message "Analysis incomplete (reached step limit). Results based on available data."
- [ ] Network failure during execution: Pause reasoning, allow manual retry
- [ ] Tool timeout (> 5s): Return timeout error, LLM can retry or skip

**C. Graceful Degradation:**
- [ ] If git commands fail (not a git repo): Protocol still runs using file system only
- [ ] If project has no package.json/Cargo.toml: Protocol adapts, uses README or other files
- [ ] Empty repository (no commits): git_log returns empty array, analysis proceeds

### 5. Testing Infrastructure (CLI Verification)

**Given** protocol execution needs testing before UI is built
**When** creating test infrastructure
**Then** `src/pages/DebugAgent.tsx` is updated (from Story 4.5.1):

**A. Add Real Tool Tests:**
- [ ] Button: "Test Real read_file Tool"
  - Prompt: "Read the package.json file and tell me the project name"
  - Verify: Model calls `read_file('package.json')`, returns correct project name
- [ ] Button: "Test Project Resurrection Protocol"
  - Loads actual tracked project from database
  - Executes full protocol with real tools
  - Displays final report in debug panel
  - Shows tool call log (each tool invocation with params)
- [ ] Button: "Test Error Handling"
  - Prompt: "Read the file nonexistent.txt"
  - Verify: Error handled gracefully, LLM receives error message, continues

**B. Debug Output Panel Updates:**
- [ ] Show tool call log: `read_file(package.json) ‚Üí 1.2KB, list_dir(src/) ‚Üí 15 files`
- [ ] Show step progression: `Step 1/5: Discover Structure ‚úì`
- [ ] Show final report with formatting
- [ ] Show execution time per step

**C. Integration Checkpoint (Before Story 4.5.3):**
- [ ] Test 1: Real tool test passes (read_file returns actual file content)
- [ ] Test 2: Full protocol test completes < 30s
- [ ] Test 3: Error handling test shows graceful degradation
- [ ] Tool call logger records all invocations correctly
- [ ] No regressions to Story 4.5.1 mock tool tests

### 6. Security Validation

**Given** tools have file system access
**When** validating security
**Then** the following tests pass:

**A. Path Traversal Protection:**
- [ ] Test: `read_file("../../etc/passwd")` ‚Üí Error: "Invalid path (outside project)"
- [ ] Test: `list_dir("/home/user/.ssh")` ‚Üí Error: "Invalid path (not tracked project)"
- [ ] Test: Symlink to /etc/passwd inside project ‚Üí Error: "Symlink attack detected"

**B. Project Validation:**
- [ ] Test: Tool call with projectId not in database ‚Üí Error: "Project not tracked"
- [ ] Test: Tool call with deleted project ‚Üí Error: "Project no longer exists"

**C. Size Limits:**
- [ ] Test: `read_file` on 5MB file ‚Üí Error: "File too large (max 1MB)"
- [ ] Test: `list_dir` on directory with 10,000 files ‚Üí Returns first 1,000, warns "Truncated"

## Tasks / Subtasks

### Backend Tasks (Rust)

- [ ] **1. Create Tools Command Module (src-tauri/src/commands/tools.rs - NEW)**
  - [ ] 1.1. Create new file: `src-tauri/src/commands/tools.rs`
  - [ ] 1.2. Add to `src-tauri/src/commands/mod.rs`: `pub mod tools;`
  - [ ] 1.3. Import required dependencies: `std::fs`, `std::path::PathBuf`, `serde::{Serialize, Deserialize}`

- [ ] **2. Implement Security Layer**
  - [ ] 2.1. Implement `validate_tool_path` helper function
  - [ ] 2.2. Add `is_path_within` check (canonical path comparison)
  - [ ] 2.3. Add symlink detection and rejection
  - [ ] 2.4. Add tracked project verification (query database)
  - [ ] 2.5. Add unit tests for path traversal scenarios

- [ ] **3. Implement read_file Command**
  - [ ] 3.1. Define command signature and structs
  - [ ] 3.2. Implement path validation using `validate_tool_path`
  - [ ] 3.3. Add file size check (max 1MB)
  - [ ] 3.4. Add binary file detection (check for null bytes)
  - [ ] 3.5. Read file content as UTF-8
  - [ ] 3.6. Error handling: not found, permission denied, binary, too large
  - [ ] 3.7. Write unit test: Read real file successfully
  - [ ] 3.8. Write unit test: Reject path traversal
  - [ ] 3.9. Write unit test: Reject binary file

- [ ] **4. Implement list_dir Command**
  - [ ] 4.1. Define `FileEntry` struct
  - [ ] 4.2. Implement path validation
  - [ ] 4.3. Read directory entries using `std::fs::read_dir`
  - [ ] 4.4. Collect metadata (size, modified time)
  - [ ] 4.5. Sort: directories first, then files (alphabetical)
  - [ ] 4.6. Filter hidden files (.git, .DS_Store, .*)
  - [ ] 4.7. Error handling: not found, not a directory
  - [ ] 4.8. Write unit test: List directory successfully
  - [ ] 4.9. Write unit test: Sort order correct

- [ ] **5. Import and Wrap git_status Command**
  - [ ] 5.1. Import from git.rs: `use crate::commands::git::{get_git_status, GitStatus};`
  - [ ] 5.2. Create tool wrapper command:
    ```rust
    #[tauri::command]
    pub async fn git_status(db: State<'_, SqlitePool>, project_path: String) -> Result<GitStatus, String> {
        validate_tool_path(&db, &project_path, ".").await?;
        get_git_status(project_path).await
    }
    ```
  - [ ] 5.3. If additional fields needed (branch, has_remote), extend GitStatus in git.rs first
  - [ ] 5.4. Error handling: Already implemented in get_git_status
  - [ ] 5.5. Write integration test: Git repo with uncommitted files
  - [ ] 5.6. Write integration test: Non-git directory

- [ ] **6. Import and Wrap git_log Command**
  - [ ] 6.1. Import from git.rs: `use crate::commands::git::{get_git_history, GitCommit};`
  - [ ] 6.2. Create tool wrapper command with limit parameter:
    ```rust
    #[tauri::command]
    pub async fn git_log(
        db: State<'_, SqlitePool>,
        project_path: String,
        limit: Option<usize>
    ) -> Result<Vec<GitCommit>, String> {
        validate_tool_path(&db, &project_path, ".").await?;
        let clamped_limit = limit.map(|l| l.min(50)); // Max 50 commits
        get_git_history(project_path, clamped_limit).await
    }
    ```
  - [ ] 6.3. Parameter validation (default 20, max 50)
  - [ ] 6.4. Error handling: Already implemented in get_git_history
  - [ ] 6.5. Write integration test: Fetch 10 commits
  - [ ] 6.6. Write integration test: Empty repository

- [ ] **7. Register Commands in Tauri (src-tauri/src/main.rs - MODIFY)**
  - [ ] 7.1. Import tools module: `use commands::tools::*;`
  - [ ] 7.2. Add commands to `.invoke_handler()`: `read_file`, `list_dir`, `git_status`, `git_log`
  - [ ] 7.3. Verify compilation: `cargo build`

### Frontend Tasks (TypeScript)

- [ ] **8. Implement Real Tool Handlers (src/lib/ai/tools/index.ts - MODIFY)**
  - [ ] 8.1. Import `invoke` from Tauri
  - [ ] 8.2. Import `projectStore` or receive projectId from context
  - [ ] 8.3. Import ToolExecutionContext type
  - [ ] 8.4. Implement read_file with context parameter
  - [ ] 8.5. Implement list_dir with context parameter
  - [ ] 8.6. Implement git_status with context parameter
  - [ ] 8.7. Implement git_log with context parameter
  - [ ] 8.8. Add error handling: Convert Tauri errors to user-friendly messages
  - [ ] 8.9. Tools receive context but don't call logger (wrapper handles it)

- [ ] **9. Create ToolExecutionContext Type (src/lib/ai/tools/types.ts - NEW)**
  - [ ] 9.1. Define ToolExecutionContext interface with projectId, mode, currentStepId
  - [ ] 9.2. Export for use in wrappers and tool handlers

- [ ] **10. Implement Context Injection Wrapper (src/lib/ai/tools/wrapper.ts - NEW)**
  - [ ] 10.1. Create `wrapToolsWithContext` function
  - [ ] 10.2. Accept tools, projectId, mode, getCurrentStepId as parameters
  - [ ] 10.3. Wrap each tool's execute function to inject context
  - [ ] 10.4. Call logToolCall automatically AFTER tool execution
  - [ ] 10.5. Return wrapped tools ready for Vercel SDK

- [ ] **11. Implement Tool Call Logger (src/lib/ai/tools/logger.ts - NEW)**
  - [ ] 11.1. Create `logToolCall` async function
  - [ ] 11.2. Integrate with reasoning store (appendToolCall method)
  - [ ] 11.3. Format tool calls: `tool_name(param1, param2)`
  - [ ] 11.4. Add timestamp for each tool call
  - [ ] 11.5. Export logger for use in wrapper

- [ ] **12. Update AI Client (src/lib/ai/client.ts - MODIFY)**
  - [ ] 12.1. Import wrapToolsWithContext
  - [ ] 12.2. Import realToolHandlers
  - [ ] 12.3. Modify createTauriLanguageModel to accept projectId and mode
  - [ ] 12.4. Get getCurrentStepId from reasoning store
  - [ ] 12.5. Call wrapToolsWithContext before passing tools to SDK
  - [ ] 12.6. Pass wrapped tools to TauriLanguageModel

- [ ] **13. Update Mock Tools (src/lib/ai/tools/mock/index.ts - MODIFY)**
  - [ ] 13.1. Add optional second parameter to all tool execute functions
  - [ ] 13.2. Make backward compatible (context parameter optional)
  - [ ] 13.3. Verify Story 4.5.1 tests still pass

- [ ] **14. Define Project Resurrection Protocol (src/lib/ai/protocols/project-resurrection.ts - NEW)**
  - [ ] 14.1. Create protocol file
  - [ ] 14.2. Define `PROJECT_RESURRECTION_PROTOCOL` constant
  - [ ] 14.3. Define all 5 steps with instructions (per AC #3.A)
  - [ ] 14.4. Export protocol for use by agent
  - [ ] 14.5. Add inline comments explaining each step's purpose

- [ ] **15. Update Debug Page with Real Tool Tests (src/pages/DebugAgent.tsx - MODIFY)**
  - [ ] 15.1. Add "Test Real read_file Tool" button and handler
  - [ ] 15.2. Add "Test Project Resurrection Protocol" button and handler
  - [ ] 15.3. Add "Test Error Handling" button and handler
  - [ ] 15.4. Update debug output panel to show tool call logs
  - [ ] 15.5. Add step progression display (Step X/5)
  - [ ] 15.6. Add execution timer per step
  - [ ] 15.7. Format final report with markdown rendering

### Integration \u0026 Testing Tasks

- [ ] **13. Security Testing**
  - [ ] 13.1. Test path traversal protection (../../etc/passwd)
  - [ ] 13.2. Test symlink attack prevention
  - [ ] 13.3. Test project validation (invalid projectId)
  - [ ] 13.4. Test file size limits (> 1MB file)
  - [ ] 13.5. Test untracked project rejection
    - Create project directory NOT in database
    - Call read_file with that project path
    - Verify error: "Project not tracked. Only tracked projects can be accessed."
  - [ ] 13.6. Test binary file rejection
    - Create 1MB .png file in test project directory
    - Call read_file("test.png")
    - Verify error: "File is binary, cannot read as text"
    - Verify file NOT loaded into memory (no 1MB allocation)
  - [ ] 13.7. Document security test results

- [ ] **14. End-to-End Protocol Testing**
  - [ ] 14.1. Run Project Resurrection protocol on real project
  - [ ] 14.2. Verify all 5 steps execute successfully
  - [ ] 14.3. Verify execution time < 30s
  - [ ] 14.4. Verify final report quality (actionable insights)
  - [ ] 14.5. Test on edge cases: empty repo, no package.json, non-git folder

- [ ] **15. Error Handling Validation**
  - [ ] 15.1. Test file not found scenario
  - [ ] 15.2. Test binary file read attempt
  - [ ] 15.3. Test non-git repo git_status call
  - [ ] 15.4. Test max steps exhaustion
  - [ ] 15.5. Verify graceful degradation for all errors

- [ ] **16. Regression Testing**
  - [ ] 16.1. Verify Story 4.5.1 mock tool tests still pass
  - [ ] 16.2. Verify existing AI context generation (Story 3.4) unaffected
  - [ ] 16.3. Run all Rust unit tests: `cargo test`
  - [ ] 16.4. Run all TypeScript tests: `npm test`

- [ ] **17. Documentation**
  - [ ] 17.1. Add inline documentation to all tool commands
  - [ ] 17.2. Document security validation approach
  - [ ] 17.3. Add protocol execution flow diagram (optional, in comments)
  - [ ] 17.4. Document tool call logging format

## Dev Notes

### Architecture: Tool Security Model

**Philosophy: Áæ© (Gi) - Righteous Code**
The tools must honor the principle of "never betray the user's trust." All file access is strictly scoped to tracked projects.

**Security Layers:**

1. **Project Validation:** Tool calls only succeed if projectId is in tracked projects database
2. **Path Validation:** All paths resolved to canonical form and checked against project root
3. **Symlink Protection:** Reject symlinks that escape project directory
4. **Size Limits:** Prevent memory exhaustion from large files
5. **Binary Detection:** Don't attempt to read binary files as text

**Critical Security Function:**
```rust
fn validate_tool_path(project_path: &str, requested_path: &str) -> Result<PathBuf, String> {
    let project_canonical = fs::canonicalize(project_path)?;
    let requested_canonical = project_canonical.join(requested_path).canonicalize()?;

    if !requested_canonical.starts_with(&project_canonical) {
        return Err("Path escapes project directory".to_string());
    }

    // Additional checks: is tracked project, no symlink attacks, etc.
    Ok(requested_canonical)
}
```

This function is called by EVERY tool before file operations.

### Reusing Existing Git Infrastructure - ARCHITECTURAL DECISION

**CRITICAL CORRECTION:** Architecture doc (line 1380-1391) originally said "MVP: Shell Commands, Post-MVP (3-month): Migrate to git2-rs" - but Story 3.2 (git-history-analysis) ALREADY implemented git2-rs integration. This decision prevents duplicate functionality.

**Decision: Reuse git2-rs from Story 3.2 (NOT shell commands)**

**Files to reference:**
- `src-tauri/src/commands/git.rs` - Existing git command implementations using git2-rs
  - `get_git_status` (lines 153-179): Returns GitStatus with is_clean, modified_files
  - `get_git_history` (lines 31-129): Returns Vec<GitCommit> with sha, author, date, message, files
  - `get_git_branch` (lines 133-149): Returns branch name or "DETACHED-HEAD"

**Approach for Story 4.5.2:**
1. **Import** existing functions from git.rs: `use crate::commands::git::{get_git_status, get_git_history, GitStatus, GitCommit};`
2. **Wrap** with tool security layer (validate_tool_path)
3. **Extend** structs if additional fields needed (e.g., add `branch`, `has_remote` to GitStatus)
4. **Do NOT** reimplement git operations with shell commands

**Rationale:**
- ‚úÖ git2-rs is already a dependency (Story 3.2, ~6 weeks ago)
- ‚úÖ More robust than shell command parsing (handles edge cases: detached HEAD, empty repos)
- ‚úÖ Faster execution (no process spawn overhead, direct libgit2 binding)
- ‚úÖ Already tested (src-tauri/src/commands/git.rs lines 218-505 have comprehensive tests)
- ‚úÖ Prevents duplicate functionality and conflicting struct definitions

**Breaking Change from Original Story:**
- Original AC #1.C-D specified shell commands: `git status --porcelain`, `git log --oneline`
- Revised AC #1.C-D: Import and reuse git2-rs functions
- Struct definitions updated to match existing git.rs structs (GitStatus, GitCommit)

**If Additional Fields Needed:**
Extend existing structs in git.rs first (one source of truth), then import:
```rust
// In git.rs (Story 3.2):
pub struct GitStatus {
    pub is_clean: bool,
    pub modified_files: Vec<String>,
    // ADD NEW FIELDS HERE if Story 4.5.2 needs them:
    pub branch: Option<String>,      // Add if needed
    pub has_remote: bool,             // Add if needed
}
```

This ensures no struct duplication and maintains consistency across the codebase.

### Project Resurrection Protocol Design

The protocol is designed to mimic how a developer would manually recover context:

**Step 1: Discover Structure**
- "What kind of project is this?" (web app, library, CLI tool)
- Map key directories to understand codebase layout

**Step 2: Read Metadata**
- "What dependencies does it use?"
- Extract from package.json, Cargo.toml, etc.

**Step 3: Analyze Git**
- "What was I last working on?"
- Recent commits + uncommitted changes reveal focus area

**Step 4: Check DEVLOG (Optional)**
- "Did I leave myself notes?"
- Manual annotations enhance git data

**Step 5: Synthesize Report**
- "Where do I start?"
- Combine all data into actionable next steps

**Key Insight:** The LLM autonomously navigates these steps using tools. We don't hard-code the analysis logic‚Äîthe model's reasoning drives it.

### Tool Call Logging for Future UI

Story 4.5.3 will build ThinkingIndicator UI showing real-time tool usage:
- "üìñ Reading package.json..."
- "üîç Analyzing git history..."
- "üìù Synthesizing context..."

To enable this, we log ALL tool calls with:
```typescript
{
  stepId: 'step-02-read-metadata',
  output: '...',  // LLM's text output
  timestamp: Date.now(),
  toolCallsMade: [
    'read_file(package.json)',
    'read_file(README.md)'
  ]
}
```

This data structure feeds directly into ProtocolViewer component (Story 4.5.3).

### Performance Considerations

**NFR Target:** Protocol execution < 30s

**Breakdown:**
- Step 1 (list_dir): ~100ms
- Step 2 (read package.json): ~50ms
- Step 3 (git_status + git_log): ~500ms
- Step 4 (read DEVLOG): ~100ms
- Step 5 (LLM synthesis): ~10-15s (depends on model speed)
- **Total:** ~12-16s (well under 30s target)

**Optimization Strategy:**
- Use shell git commands (fast) in MVP
- Future: Migrate to git2-rs for better performance (3-month plan)
- Cache file reads if LLM calls same file multiple times

### Error Handling Philosophy: ‰ªÅ (Jin) - Compassionate Craft

**User-Facing Errors:**
- ‚ùå Bad: "ENOENT: no such file or directory"
- ‚úÖ Good: "File not found: DEVLOG.md (Ronin will proceed without it)"

**Implementation:**
```typescript
catch (error) {
  if (error.includes('ENOENT')) {
    return "File not found. Continuing analysis with available data.";
  }
  return `Unexpected error: ${error}`;
}
```

All tool errors are translated to empathetic messages before being shown to LLM or user.

### Testing Strategy

**Backend Tests (Rust):**
- Unit tests for path validation (11 scenarios)
- Integration tests for git commands (real git repos)
- Security tests for path traversal (5 attack vectors)

**Frontend Tests (TypeScript):**
- Mock Tauri invoke for tool handlers
- Test tool call logging format
- Test error message transformation

**End-to-End Tests (Debug Page):**
- Manual testing via debug page
- Verify protocol execution on real tracked project
- Validate 30s performance target

### Integration Checkpoint (Before Story 4.5.3)

**Must Verify:**
1. ‚úÖ All 3 debug page tests pass
2. ‚úÖ Real read_file returns actual file content
3. ‚úÖ Project Resurrection completes < 30s
4. ‚úÖ Tool call logger records all invocations
5. ‚úÖ Security tests pass (no path traversal)
6. ‚úÖ No regressions to Story 4.5.1

**Proves:**
- Tools work end-to-end (Rust ‚Üí TypeScript ‚Üí LLM)
- Protocol execution is autonomous
- Security model is solid
- Ready for UI implementation (Story 4.5.3)

### Files Modified/Created

**Backend (Rust):**
- [NEW] `src-tauri/src/commands/tools.rs` - Tool commands with security wrapper
- [MODIFY] `src-tauri/src/commands/mod.rs` - Add tools module
- [MODIFY] `src-tauri/src/main.rs` - Register tool commands
- [OPTIONAL MODIFY] `src-tauri/src/commands/git.rs` - Extend GitStatus/GitCommit structs if additional fields needed

**Frontend (TypeScript):**
- [MODIFY] `src/lib/ai/tools/index.ts` - Replace mocks with real implementations
- [NEW] `src/lib/ai/tools/types.ts` - ToolExecutionContext interface
- [NEW] `src/lib/ai/tools/wrapper.ts` - Context injection + auto-logging wrapper
- [NEW] `src/lib/ai/tools/logger.ts` - Tool call logging
- [MODIFY] `src/lib/ai/client.ts` - Use wrapToolsWithContext
- [NEW] `src/lib/ai/protocols/project-resurrection.ts` - Protocol definition
- [MODIFY] `src/pages/DebugAgent.tsx` - Add real tool tests
- [MODIFY] `src/lib/ai/tools/mock/index.ts` - Update mocks to accept optional context parameter (backward compatible)

**Testing:**
- [NEW] `src-tauri/src/commands/tools_tests.rs` - Tool unit tests (if not inline)

### Dependencies from Previous Stories

**Story 4.5.1 Provides:**
- ‚úÖ `ReasoningProtocol` interface defined
- ‚úÖ `reasoningStore` ready for tool call logging
- ‚úÖ Vercel AI SDK client with `maxSteps` support
- ‚úÖ Mock tools as reference implementation
- ‚úÖ Debug page infrastructure

**Story 3.2 Provides:**
- ‚úÖ Git command execution infrastructure
- ‚úÖ `get_git_history` command (reusable logic)
- ‚úÖ Git repo validation

**Story 4.25.1 Provides:**
- ‚úÖ Unified AI client backend
- ‚úÖ Multi-turn message support

### Known Limitations (Acceptable for MVP)

1. **Non-recursive list_dir:** Only lists single level (not recursive)
   - Reason: Performance and complexity
   - Workaround: LLM can call list_dir multiple times for subdirectories

2. **Git shell commands (not git2-rs):** Uses `git` CLI via shell
   - Reason: Faster to implement in MVP
   - Migration plan: Story 5.X will migrate to git2-rs for better performance

3. **1MB file size limit:** Cannot read large files
   - Reason: Prevent memory exhaustion
   - Workaround: LLM can list directory to find smaller files

4. **English-only error messages:** Tool errors in English
   - Reason: Story focus, i18n is future enhancement
   - Impact: V (user) speaks English, not a blocker

## Technical Requirements

### Performance Targets

| Metric | Target | Notes |
|--------|--------|-------|
| read_file execution | < 100ms | For files < 100KB |
| list_dir execution | < 200ms | For directories < 100 files |
| git_status execution | < 500ms | Typical repos |
| git_log execution | < 1s | 50 commits |
| Full protocol execution | < 30s | All 5 steps (NFR target) |

### Security Requirements

- ‚úÖ Path traversal attacks blocked (100% prevention)
- ‚úÖ Only tracked projects accessible (database validation)
- ‚úÖ No system directory access (/etc, /home/user/.ssh)
- ‚úÖ Symlink escape attempts rejected
- ‚úÖ File size limits enforced (max 1MB)

### Error Recovery

**Scenario 1:** File not found
- Behavior: Return error to LLM, LLM adapts (skips step or tries alternative)
- User Impact: None (LLM handles gracefully)

**Scenario 2:** Not a git repo
- Behavior: git_status/git_log return error
- User Impact: Protocol continues with file system analysis only

**Scenario 3:** Max steps exhausted
- Behavior: Return partial results with message
- User Impact: User sees incomplete analysis, can retry or accept partial

## Definition of Done

- [ ] **All Tasks Complete:** 17 task sections with 90+ subtasks marked as `[x]`

- [ ] **Backend Tests Pass:**
  - [ ] Rust unit tests for all 4 tools (read_file, list_dir, git_status, git_log)
  - [ ] Security tests: 5 path traversal scenarios rejected
  - [ ] Integration tests: Git commands work on real repos
  - [ ] All existing tests pass (no regressions)

- [ ] **Frontend Tests Pass:**
  - [ ] Tool handlers invoke Tauri commands correctly
  - [ ] Tool call logger records all invocations
  - [ ] Error transformation produces user-friendly messages

- [ ] **Debug Page Verification:**
  - [ ] "Test Real read_file Tool" test passes
  - [ ] "Test Project Resurrection Protocol" completes < 30s
  - [ ] "Test Error Handling" shows graceful degradation
  - [ ] Tool call log displays correctly
  - [ ] Step progression displays (Step X/5)

- [ ] **Security Validation:**
  - [ ] Path traversal test: `../../etc/passwd` blocked
  - [ ] Symlink attack test blocked
  - [ ] Invalid project ID rejected
  - [ ] File size limit enforced (>1MB rejected)

- [ ] **Protocol Execution Verified:**
  - [ ] All 5 steps execute autonomously
  - [ ] Final report includes: Last Active Area, Current State, Next Steps
  - [ ] Attribution section present (tool calls listed)
  - [ ] Execution time < 30s on typical project

- [ ] **Integration Checkpoint (Before Story 4.5.3):**
  - [ ] All debug page tests pass
  - [ ] Tool call logging works end-to-end
  - [ ] No regressions to Story 4.5.1 or Story 3.4
  - [ ] Rust: `cargo build` succeeds, `cargo test` passes
  - [ ] TypeScript: `npm run build` succeeds, no lint errors

- [ ] **Documentation Complete:**
  - [ ] All tool commands have inline documentation
  - [ ] Security model documented
  - [ ] Protocol flow documented
  - [ ] Tool call logging format documented

## Dev Agent Record

### Agent Model Used

{{agent_model_name_version}}

### Debug Log References

### Completion Notes List

### File List
